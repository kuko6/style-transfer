---
title: Style Transfer
emoji: üë®‚Äçüé®
colorFrom: pink
colorTo: yellow
sdk: gradio
sdk_version: 4.36.1
app_file: app.py
pinned: false
---

# Style Transfer

## Cieƒæ

Cieƒæom tohto zadania bolo vytvori≈• a natr√©nova≈• model pre *Style Transfer* pomocou met√≥dy *AdaIN (Adaptive Instance Normalisation)*. Ide teda o prenos ≈°t√Ωlu z jedn√©ho obr√°zka na obsah druh√©ho obr√°zka. Pre vykonanie Style Transferu je teda potrebn√© ma≈• v≈ædy 2 vstupn√© obr√°zky - ≈°t√Ωlov√Ω a obsahov√Ω.

## D√°ta

Pre tento probl√©m sme pracovali s dvomi datasetmi. Jeden, v ktorom sa nach√°dzaj√∫ ≈°t√Ωlov√© obr√°zky a druh√Ω, v ktorom sa nach√°dzaj√∫ obsahov√© obr√°zky. Ako ≈°t√Ωlov√Ω dataset sme pou≈æili [dataset umeleck√Ωch diel z WikiArt](https://www.kaggle.com/competitions/painter-by-numbers/data) a ako obsahov√Ω dataset sme pou≈æili [dataset COCO](https://cocodataset.org/#download).

### Vzorka d√°t

![Vzorka ≈°t√Ωlov√Ωch d√°t (WikiArt dataset)](imgs/Untitled.png)

Vzorka ≈°t√Ωlov√Ωch d√°t (WikiArt dataset)

![Vzorka obsahov√Ωch d√°t (COCO dataset)](imgs/Untitled%201.png)

Vzorka obsahov√Ωch d√°t (COCO dataset)

## **Model**

Pri vytv√°ran√≠ modelu sme sa riadili ƒçl√°nkom od Huang et al. [1], v ktorom autori po prv√Ωkr√°t opisuj√∫ *Adaptive Instance Normalization* a vyu≈æitie tejto met√≥dy na *Style Transfer*. Architekt√∫ra, ktor√∫ autori pou≈æili pozost√°va z enk√≥dera, AdaIN vrstvy a dek√≥dera.

![Untitled](imgs/Untitled%202.png)

Enk√≥der je tvoren√Ω prv√Ωmi ≈°tyrmi vrstvami predtr√©novan√©ho modelu VGG-19. AdaIN vrstva predstavuje matematick√∫ oper√°ciu, do ktorej vstupuj√∫ 2 parametre a to ≈°t√Ωlov√Ω obr√°zok ($y$) a obsahov√Ω obr√°zok ($x$), ktor√© pre≈°li enk√≥derom. Oper√°cia AdaIN vyzer√° nasledovne:

$$
AdaIN(x, y) = \sigma(y)(\frac{x-\mu(x)}{\sigma(x)})+\mu(y)
$$

V oper√°cii AdaIN sa normalizovan√Ω obsahov√Ω obr√°zok ≈°k√°luje smerodajnou odch√Ωlkou ≈°t√Ωlov√©ho obr√°zku a posunie sa o stredn√∫ hodnotu ≈°t√Ωlov√©ho obr√°zku.

```python
class AdaIN(nn.Module):
    def __init__(self, epsilon=1e-5):
        super().__init__()
        self.epsilon = epsilon

    def forward(self, content: torch.Tensor, style: torch.Tensor) -> torch.Tensor:
        return (torch.mul(sigma(style, self.epsilon), ((content - mi(content)) / sigma(content, self.epsilon))) + mi(style))
```

V√Ωstup z AdaIN vrstvy je z√°rove≈à vstupom do dek√≥dera. Dek√≥der pozost√°va z rovnak√Ωch vrstiev ako enk√≥der, ale v opaƒçnom porad√≠ (zdrkadlovo), priƒçom oper√°cie MaxPooling boli nahraden√© oper√°ciami Upsample. V√Ωstupom dek√≥dera je teda kombin√°cia ≈°t√Ωlu a obsahu dvoch p√¥vodn√Ωch obr√°zkov. Enk√≥der sa potom e≈°te pou≈æ√≠va druh√Ωkr√°t pri poƒç√≠tan√≠ content loss ($L_C$) a style loss ($L_S$).

## Tr√©novanie

Pri tr√©novan√≠ sme pou≈æili optimizer Adam s learning rate 0.0001. Vysk√∫≈°ali sme r√¥zne veƒækosti batch-size (8, 4). Batch bol v tomto pr√≠pade tvoren√Ω p√°rmi obr√°zkov (≈°t√Ωlov√Ω a obsahov√Ω obr√°zok). Keƒè≈æe enk√≥der je vlastne predtr√©novan√Ω model VGG-19 (resp. jeho ƒças≈•) a AdaIN je iba matematick√° oper√°cia bez nauƒçiteƒæn√Ωch parametrov, v celom modeli sa uƒçil iba dek√≥der. 

Pre natr√©novanie dek√≥dera sa poƒç√≠tala celkov√° loss ($L$), ktor√° pozost√°va z dvoch ƒçast√≠, content a style loss.

$$
L=L_C+\lambda L_s
$$

$L_C$ predstavuje content loss, ktor√Ω opisuje vzdialenos≈• (rozdiel) medzi p√¥vodn√Ωm obr√°zkom a v√Ωstupom z AdaIN. $L_S$ zas predstavuje style loss, teda s√∫ƒçet vzdialenost√≠ strednej hodnoty a smerodajn√© odch√Ωlky v√Ωstupov jednotliv√Ωch vrstiev (aktiv√°ci√≠) enk√≥dera pre ≈°t√Ωlov√Ω a v√Ωstupn√Ω obr√°zok. Vo vz≈•ahu e≈°te figuruje parameter $\lambda$, ktor√Ω je v tomto pr√≠pade nov√Ωm hyperparametrom. √öpravou tohto parametra je mo≈æn√© urƒçi≈•, do akej miery sa m√° prenies≈• ≈°t√Ωl zo ≈°t√Ωlov√©ho obr√°zka.

```python
def content_loss(self, enc_out: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
    return F.mse_loss(enc_out, t)
    
def style_loss(self, out_activations: dict, style_activations: dict) -> torch.Tensor:
	means, sds = 0, 0
	for out_act, style_act in zip(out_activations.values(), style_activations.values()):
		means += F.mse_loss(mi(out_act), mi(style_act))
		sds += F.mse_loss(sigma(out_act), sigma(style_act))
		
	return means + sds

def loss(self, enc_out: torch.Tensor, t: torch.Tensor, out_activations: dict, style_activations: dict) -> torch.Tensor:
	self.loss_c = self.content_loss(enc_out, t)
	self.loss_s = self.style_loss(out_activations, style_activations)

	return (self.loss_c + self.lamb * self.loss_s)
```

Model sa tr√©noval v iter√°ci√°ch, priƒçom n√°≈° fin√°lny model sa tr√©noval celkovo 80000 iter√°ci√≠.

![Sn√≠mka obrazovky 2023-05-04 o 13.51.39.png](imgs/Snmka_obrazovky_2023-05-04_o_13.51.39.png)

## V√Ωsledky

**V√Ωsledky pre obr√°zky z datasetu**

![Untitled](imgs/Untitled%203.png)

![Untitled](imgs/Untitled%204.png)

![Untitled](imgs/Untitled%205.png)

---

**Nov√© obr√°zky**

![Untitled](imgs/Untitled%206.png)

## Zhodnotenie

Podƒæa v√Ωsledkov m√¥≈æeme poveda≈•, ≈æe met√≥da funguje pomerne dobre a pri v√§ƒç≈°ine testovan√Ωch obr√°zkov pren√°≈°a okrem farby aj ≈•ah ≈°tetcom, alebo dominantn√© objekty zo ≈°t√Ωlov√©ho obr√°zku.

## Referencie

[1] Huang, Xun, and Serge Belongie. "Arbitrary style transfer in real-time with adaptive instance normalization."¬†*Proceedings of the IEEE international conference on computer vision*. 2017.
